{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e728cab-a5b9-4271-9ced-985c036d5eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hivagheisari/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load spaCy model\n",
    "nlp= spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bda4b-92d6-42b1-8c6d-b7dc4b7cfc86",
   "metadata": {},
   "source": [
    "## Synonyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0fc01d-de97-4164-8ca1-3780948b7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms=set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141c7662-c17e-4c6b-b092-cf28d69aed8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto',\n",
       " 'automobile',\n",
       " 'cable_car',\n",
       " 'car',\n",
       " 'elevator_car',\n",
       " 'gondola',\n",
       " 'machine',\n",
       " 'motorcar',\n",
       " 'railcar',\n",
       " 'railroad_car',\n",
       " 'railway_car'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_synonyms('Car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b05379-3314-4da2-a23c-8432318a5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wn.synsets('Car') is [Synset('car.n.01'), Synset('car.n.02'), Synset('car.n.03'), Synset('car.n.04'), Synset('cable_car.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(f\" wn.synsets('Car') is {wn.synsets('Car')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4659b8c9-3d56-4a5f-8f36-15829c8170ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('car.n.01.car'), Lemma('car.n.01.auto'), Lemma('car.n.01.automobile'), Lemma('car.n.01.machine'), Lemma('car.n.01.motorcar')]\n",
      "[Lemma('car.n.02.car'), Lemma('car.n.02.railcar'), Lemma('car.n.02.railway_car'), Lemma('car.n.02.railroad_car')]\n",
      "[Lemma('car.n.03.car'), Lemma('car.n.03.gondola')]\n",
      "[Lemma('car.n.04.car'), Lemma('car.n.04.elevator_car')]\n",
      "[Lemma('cable_car.n.01.cable_car'), Lemma('cable_car.n.01.car')]\n"
     ]
    }
   ],
   "source": [
    "for syn in wn.synsets('Car'):\n",
    "    print(syn.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29292b6b-050d-4d66-9ec5-c4e2c016f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "auto\n",
      "automobile\n",
      "machine\n",
      "motorcar\n",
      "car\n",
      "railcar\n",
      "railway_car\n",
      "railroad_car\n",
      "car\n",
      "gondola\n",
      "car\n",
      "elevator_car\n",
      "cable_car\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "for syn in wn.synsets('Car'):\n",
    "    #print(syn.lemmas())\n",
    "    for lemma in syn.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53a628d-027d-46bd-8775-cf73047f7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmatized_words = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        lemmatized_words.append(token.lemma_)\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f8c2ce5-7146-42dd-95d4-2d6698e12a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= '\"Text\" can refer to the written words on a page, a written message, or even a broader concept of any object that can be \"read\" and interpreted. It can also refer to the act of sending a written message on a mobile phone. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e712b773-774b-47d5-a00b-e68fcde47bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"text\" can refer to the written words on a page, a written message, or even a broader concept of any object that can be \"read\" and interpreted. it can also refer to the act of sending a written message on a mobile phone. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_l=text.lower()\n",
    "text_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbccbfc-43bf-48ef-ae0f-f6f657531805",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edac5cfb-5c5f-4f1a-b71e-96fa5fe50359",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    #print((token.lemma_))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b81dede-8e51-4eee-a242-c698146969a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'refer',\n",
       " 'write',\n",
       " 'word',\n",
       " 'page',\n",
       " 'write',\n",
       " 'message',\n",
       " 'broad',\n",
       " 'concept',\n",
       " 'object',\n",
       " 'read',\n",
       " 'interpret',\n",
       " 'refer',\n",
       " 'act',\n",
       " 'send',\n",
       " 'write',\n",
       " 'message',\n",
       " 'mobile',\n",
       " 'phone']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae2cbaf-e5b0-49fa-a3f4-584bfe828c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preprocess_text(text_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0e5754-af63-48b5-aa07-ffd3b319fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_with_syn(words):\n",
    "    expand_w= words.copy()\n",
    "    for w in words:\n",
    "        expand_w.extend(get_synonyms(w))\n",
    "    return(expand_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3b38cb-59e9-41a0-9c72-7de8787d2b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'refer', 'write', 'word', 'page', 'write', 'message', 'broad', 'concept', 'object', 'read', 'interpret', 'refer', 'act', 'send', 'write', 'message', 'mobile', 'phone', 'text_edition', 'schoolbook', 'text', 'school_text', 'textbook', 'textual_matter', 'look_up', 'cite', 'advert', 'touch', 'name', 'denote', 'consult', 'bring_up', 'concern', 'bear_on', 'pertain', 'come_to', 'have-to_doe_with', 'relate', 'mention', 'refer', 'touch_on', 'publish', 'indite', 'spell', 'compose', 'write', 'save', 'pen', 'drop_a_line', 'give-and-take', 'Holy_Scripture', 'tidings', 'intelligence', 'Word', 'Holy_Writ', 'Good_Book', 'formulate', 'give_voice', 'phrase', 'Word_of_God', 'Book', 'word', 'news', 'watchword', 'word_of_honor', 'countersign', 'password', 'Bible', 'discussion', 'Christian_Bible', 'Logos', 'Scripture', 'articulate', 'Son', 'parole', 'Page', 'paginate', 'pageboy', 'Sir_Frederick_Handley_Page', 'foliate', 'varlet', 'Thomas_Nelson_Page', 'page', 'publish', 'indite', 'spell', 'compose', 'write', 'save', 'pen', 'drop_a_line', 'content', 'subject_matter', 'substance', 'message', 'across-the-board', 'large-minded', 'all-inclusive', 'tolerant', 'unsubtle', 'all-embracing', 'liberal', 'spacious', 'encompassing', 'unspecific', 'all-encompassing', 'full', 'extensive', 'blanket', 'broad', 'wide', 'panoptic', 'conception', 'concept', 'construct', 'aim', 'target', 'physical_object', 'objective', 'object', 'read', 'register', 'say', 'show', 'take', 'interpret', 'study', 'understand', 'scan', 'record', 'translate', 'learn', 'represent', 'read', 'see', 'rede', 'interpret', 'construe', 'understand', 'render', 'translate', 'look_up', 'cite', 'advert', 'touch', 'name', 'denote', 'consult', 'bring_up', 'concern', 'bear_on', 'pertain', 'come_to', 'have-to_doe_with', 'relate', 'mention', 'refer', 'touch_on', 'roleplay', 'do', 'move', 'turn', 'enactment', 'behave', 'deed', 'act', 'routine', 'number', 'bit', 'human_action', 'represent', 'playact', 'work', 'human_activity', 'play', 'dissemble', 'pretend', 'act_as', 'ship', 'broadcast', 'mail', 'commit', 'send_out', 'send_off', 'transmit', 'post', 'transport', 'place', 'direct', 'institutionalize', 'institutionalise', 'get_off', 'charge', 'air', 'beam', 'send', 'station', 'publish', 'indite', 'spell', 'compose', 'write', 'save', 'pen', 'drop_a_line', 'content', 'subject_matter', 'substance', 'message', 'Mobile', 'nomadic', 'roving', 'fluid', 'peregrine', 'Mobile_River', 'wandering', 'mobile', 'earphone', 'ring', 'phone', 'telephone', 'speech_sound', 'headphone', 'call', 'call_up', 'earpiece', 'sound', 'telephone_set']\n"
     ]
    }
   ],
   "source": [
    "print(expand_with_syn(preprocess_text(text_l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d66035-d683-4092-b7be-4f3dac617442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'write': 6, 'refer': 4, 'message': 4, 'read': 3, 'interpret': 3, 'publish': 3, 'indite': 3, 'spell': 3, 'compose': 3, 'save': 3, 'pen': 3, 'drop_a_line': 3, 'text': 2, 'word': 2, 'page': 2, 'broad': 2, 'concept': 2, 'object': 2, 'act': 2, 'send': 2, 'mobile': 2, 'phone': 2, 'look_up': 2, 'cite': 2, 'advert': 2, 'touch': 2, 'name': 2, 'denote': 2, 'consult': 2, 'bring_up': 2, 'concern': 2, 'bear_on': 2, 'pertain': 2, 'come_to': 2, 'have-to_doe_with': 2, 'relate': 2, 'mention': 2, 'touch_on': 2, 'content': 2, 'subject_matter': 2, 'substance': 2, 'understand': 2, 'translate': 2, 'represent': 2, 'text_edition': 1, 'schoolbook': 1, 'school_text': 1, 'textbook': 1, 'textual_matter': 1, 'give-and-take': 1, 'Holy_Scripture': 1, 'tidings': 1, 'intelligence': 1, 'Word': 1, 'Holy_Writ': 1, 'Good_Book': 1, 'formulate': 1, 'give_voice': 1, 'phrase': 1, 'Word_of_God': 1, 'Book': 1, 'news': 1, 'watchword': 1, 'word_of_honor': 1, 'countersign': 1, 'password': 1, 'Bible': 1, 'discussion': 1, 'Christian_Bible': 1, 'Logos': 1, 'Scripture': 1, 'articulate': 1, 'Son': 1, 'parole': 1, 'Page': 1, 'paginate': 1, 'pageboy': 1, 'Sir_Frederick_Handley_Page': 1, 'foliate': 1, 'varlet': 1, 'Thomas_Nelson_Page': 1, 'across-the-board': 1, 'large-minded': 1, 'all-inclusive': 1, 'tolerant': 1, 'unsubtle': 1, 'all-embracing': 1, 'liberal': 1, 'spacious': 1, 'encompassing': 1, 'unspecific': 1, 'all-encompassing': 1, 'full': 1, 'extensive': 1, 'blanket': 1, 'wide': 1, 'panoptic': 1, 'conception': 1, 'construct': 1, 'aim': 1, 'target': 1, 'physical_object': 1, 'objective': 1, 'register': 1, 'say': 1, 'show': 1, 'take': 1, 'study': 1, 'scan': 1, 'record': 1, 'learn': 1, 'see': 1, 'rede': 1, 'construe': 1, 'render': 1, 'roleplay': 1, 'do': 1, 'move': 1, 'turn': 1, 'enactment': 1, 'behave': 1, 'deed': 1, 'routine': 1, 'number': 1, 'bit': 1, 'human_action': 1, 'playact': 1, 'work': 1, 'human_activity': 1, 'play': 1, 'dissemble': 1, 'pretend': 1, 'act_as': 1, 'ship': 1, 'broadcast': 1, 'mail': 1, 'commit': 1, 'send_out': 1, 'send_off': 1, 'transmit': 1, 'post': 1, 'transport': 1, 'place': 1, 'direct': 1, 'institutionalize': 1, 'institutionalise': 1, 'get_off': 1, 'charge': 1, 'air': 1, 'beam': 1, 'station': 1, 'Mobile': 1, 'nomadic': 1, 'roving': 1, 'fluid': 1, 'peregrine': 1, 'Mobile_River': 1, 'wandering': 1, 'earphone': 1, 'ring': 1, 'telephone': 1, 'speech_sound': 1, 'headphone': 1, 'call': 1, 'call_up': 1, 'earpiece': 1, 'sound': 1, 'telephone_set': 1})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(expand_with_syn(preprocess_text(text_l))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d372f67a-69ac-4383-92f1-600d0ce98d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(Counter(expand_with_syn(preprocess_text(text_l))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc1076d5-8304-4714-97f8-fa2ce004a45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Counter(expand_with_syn(preprocess_text(text_l))).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60b94701-b31f-4e49-ac28-991bc6d7e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in a:\n",
    "    #print(Counter(expand_with_syn(preprocess_text(text_l)))[w])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5243c9e-37df-451c-ad35-f3cb52cd2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_enhanced_similarity(text1, text2):\n",
    "    # Preprocess and tokenize texts\n",
    "    words1 = preprocess_text(text1)\n",
    "    words2 = preprocess_text(text2)\n",
    "\n",
    "    # Expand with synonyms\n",
    "    words1_expanded = expand_with_synonyms(words1)\n",
    "    words2_expanded = expand_with_synonyms(words2)\n",
    "\n",
    "    # Count word frequencies\n",
    "    freq1 = Counter(words1_expanded)\n",
    "    freq2 = Counter(words2_expanded)\n",
    "\n",
    "    # Create a set of all unique words\n",
    "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
    "\n",
    "    # Create frequency vectors\n",
    "    vector1 = [freq1[word] for word in unique_words]\n",
    "    vector2 = [freq2[word] for word in unique_words]\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f95cef0c-03e7-4c42-91d1-71c0fd8b5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_keymatch(query,records):\n",
    "    best_score= 0\n",
    "    best_record= None\n",
    "    query_kw= set(query.lower().split())\n",
    "    for record in records:\n",
    "        record_kw= set(record.lower().split())\n",
    "        common_kw= query_kw.intersection(record_kw)\n",
    "        current_score= len(common_kw)\n",
    "        if current_score > best_score:\n",
    "            best_score= current_score\n",
    "            best_record= record\n",
    "    return best_record, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85459c08-c50b-4b9a-82f1-0812fbbce30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w= \"A RAG vector store is a database or dataset that contains vectorized data points.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d490188-05d5-44a8-a2cf-6e185705493e",
   "metadata": {},
   "source": [
    "#### ADV RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce667ffe-5b05-41e6-8d6a-0320d8058aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(text_input, records):\n",
    "    best_score =0\n",
    "    best_record=None\n",
    "    for record in records:\n",
    "        current_score = calculate_enhanced_similarity(text_input,record)\n",
    "        if current_score > best_score:\n",
    "            best_score= current_score\n",
    "            best_record= record\n",
    "\n",
    "        return best_score, best_record\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484945c5-6648-48f5-b4b3-8be7959b2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794c80b0-c038-41c6-9e59-f3a5caef12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790096b5-b89a-4c07-ae4e-784d32b696b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2545855c-3a7c-4574-94f0-2f2a9270356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beff3e39-e39c-4733-a56e-6e612d563fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 21 stored elements and shape (4, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (1, 3)\t0.281088674033753\n",
      "  (1, 6)\t0.281088674033753\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (1, 5)\t0.5386476208856763\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (3, 8)\t0.38408524091481483\n",
      "  (3, 3)\t0.38408524091481483\n",
      "  (3, 6)\t0.38408524091481483\n",
      "  (3, 2)\t0.5802858236844359\n",
      "  (3, 1)\t0.46979138557992045\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbf24b-e789-4bb9-9ffa-cf9223dc8863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3f287-ed2c-4ec5-9a22-184ac2da727f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
